Бот для отслеживания новых заявок на сайте profi.ru, со встроенным браузером Chromium и GUI PySide6.

Заказчику требуется быстро реагировать на появление новых заявок.
По его наблюдениям, самые выгодные заказы в ленте заказов доступны в течение **20 секунд**. Сайт устроен так, что на каждую заявку может ответить только 10 исполнителей, и когда все слоты заполнены, заявка исчезает из доступа.

**Цель** — программа, которая будет сообщать о новых заявках, соответствующих фильтрам заказчика.

---

## Основные трудности

1. Нельзя создать автоотклик — заказчик выбирает заявки вручную. Автоответ снижает рейтинг.
2. Время реагирования <20 секунд — окно с сайтом должно быть открыто всегда.
3. Потенциальный пользователь не готов работать через терминал, ему требуется графический интерфейс.

**Решение:** окно с браузером всегда открыто, бот только отслеживает новые заявки и уведомляет звуком.

---

## Реализация (lifestream моего рабочего процесса) - что делалось, с какими проблемами сталкивалась и какие решения применяла.

### 1. Минимальный прототип
- Встроенный браузер открывает окно с profi.ru.
- Используем **PySide6** и **QWebEngine**.
- Модули:
  - `gui/browser.py` — класс браузера
  - `gui/main_window.py` — главное окно
  - `main.py` — точка входа

Окно с браузером работает, сайт загружается корректно.


### 2.Теперь добавим в виджет кнопку старт/стоп, которая запустит обновление страницы, пусть каждые 5 секунд.
Пока добавим только сами кнопки, без логики их обработки.

В файле control_buttons.py создала виджет с двумя кнопками старт и стоп в горизонтальной раскладке.
Добавила виджет с кнопками в главное окно в main_window.py, подключила кнопки к сигналам.
Пока логика работы приложения описывается в main_window.py.

Работает, НО!!!! блок кнопок по размеру такой же, как и сам браузер, нужно добавить настройки, чтобы блок кнопок был небольшим, а браузер занимал основное пространство. Оставлю это на конец, пока реализую основные функции бота.


### 3.Теперь добавим обновление страницы по таймеру.
Будем использовать QTimer из PySide6 и функцию reload().

Добавила модуль core/refresher.py, здесь логика запуска обновления страницы
запускается с помощью QTimer.
Подключила автообновления к кнопкам в главном окне main_window.py.

### 4.Виджеты браузера и кнопок были одного размера.
Плохо, браузером неудобно пользоваться, настроила так, чтобы браузер занимал основное место в окне, а у кнопок был фиксированный размер.

### 5.Теперь задача отслеживать новые заявки.
Раз в обновление (через Refresher) будем проверять содержимое страницы (отслеживать DOM).
Хранить (пока условные ID), будем во множестве set (пока не ясен масштаб, возможно заменим на SQLite).
Если появился новый элемент, которого нет во множестве (новая заявка) - подаём сигнал (звук, уведомление).

Создала хранилище в utils/storage.py.

В core/notifier.py создала уведомления с помощью QSoundEffect, QMessageBox, QUrl. Простые звуковые файлы разместила в этой же директории.

Создала наблюдателя core/wacher.py, который связал парсинг по html странице с хранилищем id заявок и звуковым уведомлением (добавила так же и текстовое уведомление).
Для парсинга использовала библиотеку BeautifulSoup4.

Добавила в core/refresher.py в метод refresh проверку новых заявок после каждого обновления страницы.

Всё подключила в главном окне (хранилище, уведомления, наблюдателя),
запустила, работает. Но т.к. поиск пока не отлажен, бот ничего не находит, но сообщения о своей работе отправляет.

### 6.Для отслеживания ошибок создала логгер
core/logger.py, с записью в лог-файл profi_helper/logs/app.log.
Использовала стандартную библиотеку python для ведения логов logging.

### 7.С хранилищем в виде множества возникла загвоздка
При перезапуске бота информация о просмотренных заявках нигде не сохраняется. Думала о варианте с хранением в файле JSON или SQLite, но в итоге поняла, что для конкретного бота можно оставить и простое хранение в множестве.

Здесь важно, как планируется пользоваться программой:

Заказчик открывает окно программы, логинится на сайте, открывает страницу заказов, смотрит все, что есть сейчас, потом закрывает все просмотренные заявки и только потом включает бота, который и будет сообщать о новых заявках. А любая заявка, появивщаяся настранице, будет новой и нужной.

### 8.Сейчас бот ничего не находит
core/watcher.py, заказы подгружаются динамически JavaScript-ом, в HTML попадает только каркас страницы, без блоков <div class="order-card">.
Как итог - использовать BeautifulSoup неэффективно!!!. Бот ничего не сможет найти.

Вынесла парсер в отдельный модуль core/parser.py, теперь извлекать данные из вэб-страницы можно в двух режимах: 'html' - получение всей страницы и парсинг через BeautifulSoup, 'js' - выполнение JavaScript и извлечение ID заказов напрямую.

### 9.Рандомный интервал обновления
Чтобы алгоритмы сайта не обнаружили, что работает бот, сделала интерва автообновления страницы рандомным, функция из модуля utils/random_interval.py выдаёт значения от 5000 мс до 10000 мс. Обновила refresher.

### 10.Получила бан от сайта
При отладке парсинга, после 10 заходов на сайт profi.ru ограничил доступ к сайту на 1 час, потом, при повторных множественных заходах ограничил моему IP доступ на 12 часов.

Тогда я узнала, что встроенный Chromium поддерживает прокси.
Скорректировала браузер browser.py, добавила в инициализатор прокси.
Как оказалось, прокси с логином и паролем он тоже не поддерживает (сайт не грузится).
Попробовала открытые прокси без логина и пароля - они слишком медленные, не могут прогрузить сам сайт.

### 11.Встроенный Chromium не сохраняет cookies и кэш между запусками
Он не создаёт Default-профиль, поэтому все данные сессии удаляются при закрытии приложения. Нашла выход - создам явно профиль и для него задам пути сохранения данных. Тогда браузер после единичной авторизации запомнит токен и, при повторном запуске, возьмёт данные с диска.

### 12.Парсер переписала
parser.py, теперь он просматривает только первый элемент в списке.
Если этот элемент имеет в div a[data-testid], значит эту заявку пользователь ещё не видел - парсер вернёт 1 (нашёл); если в div DIVIDER (разделитель) - значит все заявки просмотрены и новых нет, парсер вернёт 0.
Так логика проще и хранить ничего не нужно.

### 13.Страница грузится долго!
Парсер должен подождать, пока она прогрузится полностью, иначе результат выдаёт неверный!
Переписала refresher так, что при обновлении QWebEngineView.page() ждёт сигнала loadFinished и только после этого вызывает watcher.

### 14.Войти в сами заявки из окна бота нельзя
Проверила, сессия сохраняется корректно, НО!!!! войти в сами заявки из окна бота нельзя, они не кликабельны.

Нашла способ, в browser.py добавила user-agent.
Насколько поняла, это строка, которую браузер отправляет сайту при каждом HTTP-запросе. Она сообщает сайту какой это браузер, операционная система и др.

### 15.Не помогло, карточки не грузятся.

Включила поддержку SameSite-куков, отключила автоапгрейд смешанного контента и разрешила небезопасный JS.

Добавила локализацию и кэш, чтобы сайт видел, что браузер русский и умеет хранить кэш на диске.

Так же в браузер добавила метод open_devtools() для открытия DevTools, метод привязала к кнопке в control_buttons, чтобы понять причину, почему не открываются карточки заявок во встроенном браузере.

Нет, не вышло, у сайта profi.ru есть встроенная защина от нестандартных браузеров, он ограничивает функционал. Можно переписать на selenium.

### 16.Создала .exe папку
Для удобного запуска бота была создана версия в виде .exe:

Скачайте архив репозитория на свой компьютер.

Перейдите в папку с готовым приложением:
```
profi_ru_bot\profi_helper\dist\
```

Запустите файл:
```
ProfiHelperBot.exe
```
### 17.Внесла финальные правки.
После дня активного использования бота, по просьбе заказчика, внесла небольшие корректировки:
 - кнопки управления перенесла из нижнего левого угла в правый верхний;
 - добавила повтор звукового уведомления до тех пор, пока не будет нажата кнопка стоп.

Итоговой работой заказчик остался доволен.

### Итог: функционал, который работает
1. Переход в личный кабинет с сохранением сессии.
2. Мониторинг новых заявок с уведомлением звуком.
3. Необходимое условие: для отклика на заявку нужно открыть отдельное окно браузера.

### Ограничения
- Нельзя кликать по карточкам заявок во встроенном браузере.
- Сайт profi.ru ограничивает функционал встроенного Chromium.
