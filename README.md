# profi_ru_bot
Бот для отслеживания новых заявок на сайте profi.ru, со встроенным браузером Chromium и GUI PySide6.

Заказчику требуется быстро реагировать на появление новых заявок.
По его наблюдениям, самые выгодные заказы в ленте заказов доступны в течении 20 секунд. Сайт устроен так, что на каждую заявку может ответитить только 10
возможных исполнителей, когда все слоты заполнены, заявка из доступа исчезает.
Как итог - заказчик не успевает реагировать и откликаться на выгодные заказы.
Ему требуется программа, которая будет сообщать ему о новых заявках, соответствующих выставленным фильтрам.

Напишу программу, которая решит поставленные задачи.

Основные трудности:
1.Нельзя создать автоотклик - заказчик не отвечает на все заявки подряд, его опыт позволят быстро оценить заявку и принять решение стоит ли на неё реагировать.

В случае ответа на все заявки подряд падает рейтинг, что неприемлимо.

2.Время реагирования <20 секунд.

Делаем вывод - окно с сайтом должно быть открыто всегда.

Этот вариант позволит отслеживать новые заявки и отвечать в том же окне браузера.

На данный момент вижу такое решение:

При запуске программы встроенный браузер будет открывать окно,
в этом окне пользователь перейдёт на сайт профи.ру (можно прописать автоматический переход на нужный сайт), залогинится, перейдёт на страницу заявок и настроит фильтры.
В самом окне помощника будет встроена кнопка старт/стоп.
При нажатии на старт бот начнёт обновлять страницу и при появлении новой заявки по заданным фильтрам включит звуковой сигнал.
После этого пользователю нужно будет нажать на кнопку стоп и он получит возможность в этом же окне ответить на заявку.

Ниже буду описывать реализацию, идеи и проблемы, с которыми буду сталкиваться.

1.Начнём с минимального прототипа:
Во встроенном браузере откроем окно - в этом окне отрыть profi.ru
Для этого используем PySide6 и встроенный в него QWebEngine.

Создала модуль gui, а в нём browser.py - описала класс встроенного браузера,
main_window.py - класс главного окна (пока без кнопок, но с заданным адресом
страницы сайта 'https://profi.ru/').
Точка входа в файле main.py.

Отлично, окно с браузером заработало, сайт profi.ru загружается и работает корректно.

2.Теперь добавим в виджет кнопку старт/стоп, которая запустит обновление страницы, пусть каждые 5 секунд.
Пока добавим только сами кнопки, без логики их обработки.

В файле control_buttons.py создала виджет с двумя кнопками старт и стоп в горизонтальной раскладке.
Добавила виджет с кнопками в главное окно в main_window.py, подключила кнопки к сигналам.
Пока логика работы приложения описывается в main_window.py.

Работает, НО!!!! блок кнопок по размеру такой же, как и сам браузер, нужно добавить настройки, чтобы блок кнопок был небольшим, а браузер занимал основное пространство. Оставлю это на конец, пока реализую основные функции бота.


3.Теперь добавим обновление страницы по таймеру.
Будем использовать QTimer из PySide6 и функцию reload().

Добавила модуль core/refresher.py, здесь логика запуска обновления страницы
запускается с помощью QTimer.
Подключила автообновления к кнопкам в главном окне main_window.py.

4.Виджеты браузера и кнопок были одного размера, что плохо, браузером неудобно пользоваться, настроила так, чтобы браузер занимал основное место в окне, а у кнопок был фиксированный размер.

5.Теперь задача отслеживать новые заявки.
Раз в обновление (через Refresher) будем проверять содержимое страницы (отслеживать DOM).
Хранить (пока условные ID), будем во множестве set (пока не ясен масштаб, возможно заменим на SQLite).
Если появился новый элемент, которого нет во множестве (новая заявка) - подаём сигнал (звук, уведомление).

Создала хранилище в utils/storage.py.

В core/notifier.py создала уведомления с помощью QSoundEffect, QMessageBox, QUrl. Простые звуковые файлы разместила в этой же директории.

Создала наблюдателя core/wacher.py, который связал парсинг по html странице с хранилищем id заявок и звуковым уведомлением (добавила так же и текстовое уведомление).
Для парсинга использовала библиотеку BeautifulSoup4.

Добавила в core/refresher.py в метод refresh проверку новых заявок после каждого обновления страницы.

Всё подключила в главном окне (хранилище, уведомления, наблюдателя),
запустила, работает. Но т.к. поиск пока не отлажен, бот ничего не находит, но сообщения о своей работе отправляет.

6.Для отслеживания ошибок создала логгер core/logger.py, с записью в лог-файл profi_helper/logs/app.log.
Использовала стандартную библиотеку python для ведения логов logging.

7.С хранилищем в виде множества возникла загвоздка - при перезапуске бота информация о просмотренных заявках нигде не сохраняется. Думала о варианте с хранением в файле JSON или SQLite, но в итоге поняла, что для конкретного бота можно оставить и простое хранение в множестве.

Здесь важно, как планируется пользоваться программой:

Заказчик открывает окно программы, логинится на сайте, открывает страницу заказов, смотрит все, что есть сейчас, потом закрывает все просмотренные заявки и только потом включает бота, который и будет сообщать о новых заявках. А любая заявка, появивщаяся настранице, будет новой и нужной.

8.core/watcher.py
Сейчас бот ничего не находит из-за того, что заказы подгружаются динамически JavaScript-ом, в HTML попадает только каркас страницы, без блоков <div class="order-card">.
Как итог - использовать BeautifulSoup неэффективно!!!. Бот ничего не сможет найти.

Вынесла парсер в отдельный модуль core/parser.py, теперь извлекать данные из вэб-страницы можно в двух режимах: 'html' - получение всей страницы и парсинг через BeautifulSoup, 'js' - выполнение JavaScript и извлечение ID заказов напрямую.

9.Чтобы алгоритмы сайта не обнаружили, что работает бот, сделала интерва автообновления страницы рандомным, функция из модуля utils/random_interval.py выдаёт значения от 5000 мс до 10000 мс. Обновила refresher.

10.При отладке парсинга, после 10 заходов на сайт profi.ru ограничил доступ к сайту на 1 час, потом, при повторных множественных заходах ограничил моему IP доступ на 12 часов.

Тогда я узнала, что встроенный Chromium поддерживает прокси.
Скорректировала браузер browser.py, добавила в инициализатор прокси.
Как оказалось, прокси с логином и паролем он тоже не поддерживает (сайт не грузится).
Попробовала открытые прокси без логина и пароля - они слишком медленные, не могут прогрузить сам сайт.

11.Встроенный Chromium не сохраняет cookies и кэш между запусками: он не создаёт Default-профиль, поэтому все данные сессии удаляются при закрытии приложения. Нашла выход - создам явно профиль и для него задам пути сохранения данных. Тогда браузер после единичной авторизации запомнит токен и, при повторном запуске, возьмёт данные с диска.

12.Парсер переписала parser.py, теперь он просматривает только первый элемент в списке.
Если этот элемент имеет в div a[data-testid], значит эту заявку пользователь ещё не видел - парсер вернёт 1 (нашёл); если в div DIVIDER (разделитель) - значит все заявки просмотрены и новых нет, парсер вернёт 0.
Так логика проще и хранить ничего не нужно.

13.Страница грузится долго!
Парсер должен подождать, пока она прогрузится полностью, иначе результат выдаёт неверный!
Переписала refresher так, что при обновлении QWebEngineView.page() ждёт сигнала loadFinished и только после этого вызывает watcher.

14.Проверила, сессия сохраняется корректно, НО!!!! войти в сами заявки из окна бота нельзя, они не кликабельны, что неприемлимо.

Нашла способ, в browser.py добавила user-agent.
Насколько поняла, это строка, которую браузер отправляет сайту при каждом HTTP-запросе. Она сообщает сайту какой это браузер, операционная система и др.

15.Не помогло, карточки не грузятся.

Включила поддержку SameSite-куков, отключила автоапгрейд смешанного контента и разрешила небезопасный JS.

Добавила локализацию и кэш, чтобы сайт видел, что браузер русский и умеет хранить кэш на диске.

Так же в браузер добавила метод open_devtools() для открытия DevTools, метод привязала к кнопке в control_buttons, чтобы понять причину, почему не открываются карточки заявок во встроенном браузере.

Нет, не вышло, у сайта profi.ru есть встроенная защина от нестандартных браузеров, он ограничивает функционал.

Пока удалось реализовать:
1. Переход сразу в личный кабинет с сохранением активной учётной записи.
2. Бот мониторит новые заявки и уведомляет о них звуковым сигналом.
Этим ботом можно пользоваться, но параллельно нужно держать ещё одно залгиненное окно для ответа на заявку, потому что сайт ограничивает действия во встроенном браузере.

Создам .exe и отправлю пока так, буду думать дальше (частично удалось реализовать запросы заказчика).
